* sample the peak speed when sending message during 5 seconds, and then,
 ensures that it never goes beyond that. (OpenMPI's fifos can't handle it anyway...)
* SRA001125 freezes with 32 cores on ls30. (find the bug, fixed with --mca btl ^sm, but it is rather slow.)
* the current problem with extension: several MPI processes are extending the
 very same region, thus sending messages to the same exact MPI rank. the rank
 is then running out of fifos, and the sm btl hangs. LOL


* increase overall speed with regular interval between barriers and messages sent ?

* add progress when distributing reads.
* add progress when attaching reads.
* don'T underestimate maxSpeed -- use a distinct timestamp in each MPI process

* add a DEFINE for the Isend or Send.
* essayer plusieurs valeurs de p√©riodes pour les barriers.
* remove commented c++ code
* add progression for fusion in stdout.
* add an early-stop technology (To speed up the process.)


* possibly use a map<,> to hold information on path lengths.
* use only the MODE constants for modes.
* load paired reads. (test on SpPaired)
* use paired-end reads. to resolve repeats. (teste on SpPaired)
* speed hack:   when extending reverse-complement paths, only thread reads at the ~1000 last vertices.
* commit results for Human genome chromosome 1 unpaired. 50 bp reads.
* commit results for SRA001125 unpaired.

* do some merging between contigs (test on Ecoli400 dataset.)
* support 454's homopolymers. LOL (use the SRA003611 454 data)
* support polymorphic genomes (which data to use, simulated data?)
* move verification of an invalid file before the calibration
